name: BDD Personalization Tests

on:
  push:
    branches: [ main, develop, feature/** ]
    paths:
      - 'src/**'
      - 'build.gradle.kts'
      - 'src/test/resources/features/**'
      - '.github/workflows/bdd-personalization-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'src/**'
      - 'build.gradle.kts'
      - 'src/test/resources/features/**'
      - '.github/workflows/bdd-personalization-tests.yml'
  schedule:
    # Run nightly at 2 AM UTC for regression testing
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test Suite to Run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - bdd-only
          - personalization-only
          - performance-only
      environment:
        description: 'Test Environment'
        required: false
        default: 'test'
        type: choice
        options:
          - test
          - staging
          - integration

env:
  JAVA_VERSION: '21'
  GRADLE_OPTS: "-Dorg.gradle.jvmargs=-Xmx2048m -Dorg.gradle.daemon=false"

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      test-strategy: ${{ steps.strategy.outputs.strategy }}
      should-run-performance: ${{ steps.strategy.outputs.performance }}
      matrix: ${{ steps.matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine test strategy
        id: strategy
        run: |
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "strategy=full" >> $GITHUB_OUTPUT
            echo "performance=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "strategy=${{ github.event.inputs.test_suite }}" >> $GITHUB_OUTPUT
            echo "performance=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "strategy=fast" >> $GITHUB_OUTPUT
            echo "performance=false" >> $GITHUB_OUTPUT
          else
            echo "strategy=standard" >> $GITHUB_OUTPUT
            echo "performance=false" >> $GITHUB_OUTPUT
          fi

      - name: Setup test matrix
        id: matrix
        run: |
          if [[ "${{ steps.strategy.outputs.strategy }}" == "performance-only" ]]; then
            echo 'matrix=["performance"]' >> $GITHUB_OUTPUT
          elif [[ "${{ steps.strategy.outputs.strategy }}" == "bdd-only" ]]; then
            echo 'matrix=["bdd-core", "bdd-edge-cases", "bdd-mobile"]' >> $GITHUB_OUTPUT
          elif [[ "${{ steps.strategy.outputs.strategy }}" == "personalization-only" ]]; then
            echo 'matrix=["personalization-core", "personalization-advanced"]' >> $GITHUB_OUTPUT
          else
            echo 'matrix=["unit", "integration", "bdd-core", "bdd-edge-cases", "bdd-mobile", "personalization-core", "personalization-advanced"]' >> $GITHUB_OUTPUT
          fi

  build:
    runs-on: ubuntu-latest
    needs: setup
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'corretto'

      - name: Cache Gradle dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.gradle/caches
            ~/.gradle/wrapper
            build/kotlin
          key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle.kts', 'gradle/wrapper/gradle-wrapper.properties') }}
          restore-keys: |
            ${{ runner.os }}-gradle-

      - name: Make gradlew executable
        run: chmod +x ./gradlew

      - name: Build application
        run: ./gradlew build -x test --parallel --build-cache

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            build/libs/
            build/classes/
          retention-days: 1

  test-suite:
    runs-on: ubuntu-latest
    needs: [setup, build]
    strategy:
      fail-fast: false
      matrix:
        test-type: ${{ fromJson(needs.setup.outputs.matrix) }}
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: testpassword
          MYSQL_DATABASE: welcomer_test
          MYSQL_USER: testuser
          MYSQL_PASSWORD: testpass
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK ${{ env.JAVA_VERSION }}
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: 'corretto'

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: build/

      - name: Cache Gradle dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.gradle/caches
            ~/.gradle/wrapper
            build/kotlin
          key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle.kts', 'gradle/wrapper/gradle-wrapper.properties') }}
          restore-keys: |
            ${{ runner.os }}-gradle-

      - name: Wait for services
        run: |
          echo "Waiting for MySQL..."
          until mysqladmin ping -h localhost -P 3306 -u root -ptestpassword --silent; do
            sleep 2
          done
          echo "Waiting for Redis..."
          until redis-cli -h localhost -p 6379 ping; do
            sleep 2
          done

      - name: Run Unit Tests
        if: matrix.test-type == 'unit'
        run: |
          ./gradlew test --tests "com.welcomer.welcome.**" --exclude-tests "*Bdd*" --exclude-tests "*Integration*" \
            --parallel --continue \
            --info \
            -PtestType=unit
        env:
          SPRING_PROFILES_ACTIVE: test
          SPRING_DATASOURCE_URL: jdbc:mysql://localhost:3306/welcomer_test
          SPRING_DATASOURCE_USERNAME: testuser
          SPRING_DATASOURCE_PASSWORD: testpass
          SPRING_DATA_REDIS_HOST: localhost
          SPRING_DATA_REDIS_PORT: 6379

      - name: Run Integration Tests
        if: matrix.test-type == 'integration'
        run: |
          ./gradlew test --tests "*Integration*" \
            --parallel --continue \
            --info \
            -PtestType=integration
        env:
          SPRING_PROFILES_ACTIVE: test
          SPRING_DATASOURCE_URL: jdbc:mysql://localhost:3306/welcomer_test
          SPRING_DATASOURCE_USERNAME: testuser
          SPRING_DATASOURCE_PASSWORD: testpass
          SPRING_DATA_REDIS_HOST: localhost
          SPRING_DATA_REDIS_PORT: 6379

      - name: Run BDD Core Tests
        if: matrix.test-type == 'bdd-core'
        run: |
          ./gradlew test --tests "*NewUserPersonalization*" \
            --tests "*PowerUserPersonalization*" \
            --tests "*ContextualPersonalization*" \
            --parallel --continue \
            --info \
            -PtestType=bdd-core \
            -Dcucumber.options="--tags '@core'"
        env:
          SPRING_PROFILES_ACTIVE: test
          BDD_TEST_MODE: fast

      - name: Run BDD Edge Cases Tests  
        if: matrix.test-type == 'bdd-edge-cases'
        run: |
          ./gradlew test --tests "*EdgeCasePersonalization*" \
            --tests "*ErrorHandling*" \
            --tests "*ApiTesting*" \
            --parallel --continue \
            --info \
            -PtestType=bdd-edge \
            -Dcucumber.options="--tags '@edge-case or @error-handling'"
        env:
          SPRING_PROFILES_ACTIVE: test
          BDD_TEST_MODE: comprehensive

      - name: Run BDD Mobile Tests
        if: matrix.test-type == 'bdd-mobile'
        run: |
          ./gradlew test --tests "*MobilePersonalization*" \
            --tests "*CrossDevice*" \
            --tests "*AccessibilityPersonalization*" \
            --parallel --continue \
            --info \
            -PtestType=bdd-mobile \
            -Dcucumber.options="--tags '@mobile or @cross-device or @accessibility'"
        env:
          SPRING_PROFILES_ACTIVE: test
          BDD_TEST_MODE: device-focused

      - name: Run Personalization Core Tests
        if: matrix.test-type == 'personalization-core'
        run: |
          ./gradlew test --tests "*FeedPersonalization*" \
            --tests "*TopicRelevance*" \
            --tests "*ContentScoring*" \
            --parallel --continue \
            --info \
            -PtestType=personalization
        env:
          SPRING_PROFILES_ACTIVE: test
          PERSONALIZATION_TEST_MODE: core

      - name: Run Personalization Advanced Tests
        if: matrix.test-type == 'personalization-advanced'
        run: |
          ./gradlew test --tests "*RealTimePersonalization*" \
            --tests "*ABTesting*" \
            --tests "*FeedDiversity*" \
            --parallel --continue \
            --info \
            -PtestType=personalization-advanced
        env:
          SPRING_PROFILES_ACTIVE: test
          PERSONALIZATION_TEST_MODE: advanced

      - name: Run Performance Tests
        if: matrix.test-type == 'performance' && needs.setup.outputs.should-run-performance == 'true'
        run: |
          ./gradlew test --tests "*PerformanceTesting*" \
            --parallel --continue \
            --info \
            -PtestType=performance
        env:
          SPRING_PROFILES_ACTIVE: test
          PERFORMANCE_TEST_MODE: enabled
          JVM_ARGS: -Xmx4g -XX:+UseG1GC

      - name: Generate Test Reports
        if: always()
        run: |
          # Ensure test reports are generated
          ./gradlew testReportAggregation || true
          
          # Create comprehensive test summary
          mkdir -p build/reports/aggregated
          
          # Copy all test results for aggregation
          find build/test-results -name "*.xml" -exec cp {} build/reports/aggregated/ \; 2>/dev/null || true
          find build/reports -name "*.json" -exec cp {} build/reports/aggregated/ \; 2>/dev/null || true

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            build/reports/
            build/test-results/
            build/reports/cucumber/
          retention-days: 30

      - name: Upload Performance Artifacts
        if: matrix.test-type == 'performance' && always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: |
            build/reports/performance/
            build/reports/jvm-metrics/
          retention-days: 30

  # Aggregate results and generate comprehensive report
  report:
    runs-on: ubuntu-latest
    needs: [setup, test-suite]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts/

      - name: Set up Node.js for reporting
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Generate Comprehensive Test Report
        run: |
          # Create report generation script
          cat > generate-report.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          function generateReport() {
            const reportData = {
              summary: {
                timestamp: new Date().toISOString(),
                total_tests: 0,
                passed: 0,
                failed: 0,
                skipped: 0,
                duration: 0,
                test_suites: []
              },
              details: {}
            };
            
            // Process test results from each matrix job
            const artifactDir = 'test-artifacts';
            const testTypes = ['unit', 'integration', 'bdd-core', 'bdd-edge-cases', 'bdd-mobile', 'personalization-core', 'personalization-advanced', 'performance'];
            
            testTypes.forEach(testType => {
              const testResultsPath = path.join(artifactDir, `test-results-${testType}`);
              if (fs.existsSync(testResultsPath)) {
                console.log(`Processing results for: ${testType}`);
                
                const suiteData = {
                  name: testType,
                  tests: 0,
                  passed: 0,
                  failed: 0,
                  skipped: 0,
                  duration: 0,
                  features: []
                };
                
                // Process XML test results
                const testResultsDir = path.join(testResultsPath, 'test-results');
                if (fs.existsSync(testResultsDir)) {
                  fs.readdirSync(testResultsDir).forEach(file => {
                    if (file.endsWith('.xml')) {
                      try {
                        const content = fs.readFileSync(path.join(testResultsDir, file), 'utf8');
                        // Basic XML parsing for test counts
                        const tests = (content.match(/tests="(\d+)"/)?.[1] || 0);
                        const failures = (content.match(/failures="(\d+)"/)?.[1] || 0);
                        const skipped = (content.match(/skipped="(\d+)"/)?.[1] || 0);
                        const time = parseFloat(content.match(/time="([\d.]+)"/)?.[1] || 0);
                        
                        suiteData.tests += parseInt(tests);
                        suiteData.failed += parseInt(failures);
                        suiteData.skipped += parseInt(skipped);
                        suiteData.passed += parseInt(tests) - parseInt(failures) - parseInt(skipped);
                        suiteData.duration += time;
                      } catch (e) {
                        console.error(`Error processing ${file}:`, e.message);
                      }
                    }
                  });
                }
                
                // Process Cucumber JSON results
                const cucumberDir = path.join(testResultsPath, 'reports', 'cucumber');
                if (fs.existsSync(cucumberDir)) {
                  fs.readdirSync(cucumberDir).forEach(file => {
                    if (file.endsWith('.json')) {
                      try {
                        const content = fs.readFileSync(path.join(cucumberDir, file), 'utf8');
                        const features = JSON.parse(content);
                        
                        features.forEach(feature => {
                          const featureData = {
                            name: feature.name,
                            scenarios: feature.elements?.length || 0,
                            passed: 0,
                            failed: 0,
                            skipped: 0
                          };
                          
                          feature.elements?.forEach(scenario => {
                            const steps = scenario.steps || [];
                            const hasFailure = steps.some(step => step.result?.status === 'failed');
                            const hasSkipped = steps.some(step => step.result?.status === 'skipped');
                            
                            if (hasFailure) featureData.failed++;
                            else if (hasSkipped) featureData.skipped++;
                            else featureData.passed++;
                          });
                          
                          suiteData.features.push(featureData);
                        });
                      } catch (e) {
                        console.error(`Error processing Cucumber ${file}:`, e.message);
                      }
                    }
                  });
                }
                
                reportData.summary.total_tests += suiteData.tests;
                reportData.summary.passed += suiteData.passed;
                reportData.summary.failed += suiteData.failed;
                reportData.summary.skipped += suiteData.skipped;
                reportData.summary.duration += suiteData.duration;
                reportData.summary.test_suites.push(suiteData);
                reportData.details[testType] = suiteData;
              }
            });
            
            // Calculate success rate
            reportData.summary.success_rate = reportData.summary.total_tests > 0 
              ? ((reportData.summary.passed / reportData.summary.total_tests) * 100).toFixed(2)
              : 0;
              
            return reportData;
          }
          
          // Generate and save report
          const report = generateReport();
          fs.writeFileSync('test-report.json', JSON.stringify(report, null, 2));
          
          // Generate HTML report
          const htmlReport = `
          <!DOCTYPE html>
          <html>
          <head>
            <title>BDD Personalization Test Report</title>
            <style>
              body { font-family: Arial, sans-serif; margin: 20px; }
              .header { background-color: #f4f4f4; padding: 20px; border-radius: 5px; }
              .summary { display: flex; justify-content: space-around; margin: 20px 0; }
              .metric { text-align: center; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
              .passed { background-color: #d4edda; color: #155724; }
              .failed { background-color: #f8d7da; color: #721c24; }
              .skipped { background-color: #fff3cd; color: #856404; }
              .suite { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
              .feature { margin: 10px 0; padding: 10px; background-color: #f9f9f9; border-radius: 3px; }
              table { width: 100%; border-collapse: collapse; margin: 10px 0; }
              th, td { padding: 8px; text-align: left; border: 1px solid #ddd; }
              th { background-color: #f4f4f4; }
            </style>
          </head>
          <body>
            <div class="header">
              <h1>BDD Personalization Test Report</h1>
              <p>Generated: ${report.summary.timestamp}</p>
              <p>Total Duration: ${report.summary.duration.toFixed(2)}s</p>
            </div>
            
            <div class="summary">
              <div class="metric">
                <h3>Total Tests</h3>
                <h2>${report.summary.total_tests}</h2>
              </div>
              <div class="metric passed">
                <h3>Passed</h3>
                <h2>${report.summary.passed}</h2>
              </div>
              <div class="metric failed">
                <h3>Failed</h3>
                <h2>${report.summary.failed}</h2>
              </div>
              <div class="metric skipped">
                <h3>Skipped</h3>
                <h2>${report.summary.skipped}</h2>
              </div>
              <div class="metric">
                <h3>Success Rate</h3>
                <h2>${report.summary.success_rate}%</h2>
              </div>
            </div>
            
            ${report.summary.test_suites.map(suite => `
              <div class="suite">
                <h3>${suite.name.toUpperCase()} Test Suite</h3>
                <table>
                  <tr>
                    <th>Tests</th>
                    <th>Passed</th>
                    <th>Failed</th>
                    <th>Skipped</th>
                    <th>Duration</th>
                  </tr>
                  <tr>
                    <td>${suite.tests}</td>
                    <td class="passed">${suite.passed}</td>
                    <td class="failed">${suite.failed}</td>
                    <td class="skipped">${suite.skipped}</td>
                    <td>${suite.duration.toFixed(2)}s</td>
                  </tr>
                </table>
                
                ${suite.features.map(feature => `
                  <div class="feature">
                    <h4>${feature.name}</h4>
                    <p>Scenarios: ${feature.scenarios} | Passed: ${feature.passed} | Failed: ${feature.failed} | Skipped: ${feature.skipped}</p>
                  </div>
                `).join('')}
              </div>
            `).join('')}
          </body>
          </html>
          `;
          
          fs.writeFileSync('test-report.html', htmlReport);
          
          console.log('Report Summary:');
          console.log(`Total Tests: ${report.summary.total_tests}`);
          console.log(`Passed: ${report.summary.passed}`);
          console.log(`Failed: ${report.summary.failed}`);
          console.log(`Success Rate: ${report.summary.success_rate}%`);
          EOF
          
          # Generate the report
          node generate-report.js

      - name: Upload Comprehensive Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: |
            test-report.json
            test-report.html
          retention-days: 90

      - name: Comment PR with Test Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            if (!fs.existsSync('test-report.json')) {
              console.log('Test report not found, skipping PR comment');
              return;
            }
            
            const report = JSON.parse(fs.readFileSync('test-report.json', 'utf8'));
            const emoji = report.summary.failed === 0 ? 'âœ…' : 'âŒ';
            const status = report.summary.failed === 0 ? 'All tests passed!' : `${report.summary.failed} tests failed`;
            
            const comment = `## ${emoji} BDD Personalization Test Results
            
            **${status}**
            
            ### Summary
            - **Total Tests:** ${report.summary.total_tests}
            - **Passed:** ${report.summary.passed} âœ…
            - **Failed:** ${report.summary.failed} âŒ
            - **Skipped:** ${report.summary.skipped} â­ï¸
            - **Success Rate:** ${report.summary.success_rate}%
            - **Duration:** ${report.summary.duration.toFixed(2)}s
            
            ### Test Suites
            ${report.summary.test_suites.map(suite => 
              `- **${suite.name}**: ${suite.passed}/${suite.tests} passed (${suite.failed} failed, ${suite.skipped} skipped)`
            ).join('\n')}
            
            ### Coverage Areas Tested
            - âœ… New User Personalization
            - âœ… Power User Personalization  
            - âœ… Mobile & Cross-Device Experience
            - âœ… Real-time Adaptation
            - âœ… A/B Testing Integration
            - âœ… Accessibility & Inclusive Design
            - âœ… Performance & Load Testing
            - âœ… Edge Cases & Error Handling
            
            ðŸ“Š [View Detailed Report](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
            `;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Notification job for failures
  notify:
    runs-on: ubuntu-latest
    needs: [test-suite, report]
    if: failure() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    steps:
      - name: Notify on failure
        run: |
          echo "ðŸš¨ BDD Personalization tests failed on main branch!"
          echo "Workflow: ${{ github.workflow }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Commit: ${{ github.sha }}"
          # Here you would typically integrate with Slack, Teams, or email notifications
          # Example: curl -X POST -H 'Content-type: application/json' --data '{"text":"BDD tests failed!"}' $SLACK_WEBHOOK_URL